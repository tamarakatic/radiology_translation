{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.read_csv('../data/processed/temple_radio_1_2_sentences_with_translation.csv')\n",
    "sent_embeddings = genfromtxt('../data/processed/temple_radio_1_2_sentence_embeddings.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = sentences[(sentences['Translation'] == 'The liver is enlarged.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent_embeddings = sent_embeddings[pos_sent.index, :]\n",
    "neg_sent = sentences.drop(pos_sent.index)\n",
    "neg_sent_embeddings = sent_embeddings[neg_sent.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sent_embeddings = sent_embeddings[neg_sent.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = pos_sent.reset_index(drop=True)\n",
    "neg_sent = neg_sent.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sent_df = pd.concat([pos_sent, neg_sent]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = [1 for p in range(len(pos_sent_embeddings))]\n",
    "y_neg = [0 for n in range(len(neg_sent_embeddings))]\n",
    "\n",
    "pos_df = pd.DataFrame(pos_sent_embeddings)\n",
    "pos_df['class'] = y_pos\n",
    "\n",
    "neg_df = pd.DataFrame(neg_sent_embeddings)\n",
    "neg_df['class'] = y_neg\n",
    "\n",
    "pos_df = pos_df.reset_index(drop=True)\n",
    "neg_df = neg_df.reset_index(drop=True)\n",
    "\n",
    "new_df = pd.concat([pos_df, neg_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['sentence'] = new_sent_df['Sentence']\n",
    "new_df['translation'] = new_sent_df['Translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_df[[\"class\"]]\n",
    "X = new_df.drop([\"class\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix score:\n",
      "[[226   4]\n",
      " [  7  13]]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "acc_scores, f1_scores = [], []\n",
    "i = 0\n",
    "conf_scores = []\n",
    "\n",
    "for train, test in skf.split(X, y): # Provides train/test indices to split data in train/test sets.\n",
    "    clf = LogisticRegression(random_state=0, max_iter=1000).fit(X.drop([\"sentence\", \"translation\"], axis = 1).loc[train], y.loc[train].values.ravel())\n",
    "    y_pred = clf.predict(X.drop([\"sentence\", \"translation\"], axis = 1).loc[test])\n",
    "    \n",
    "    df_skf = pd.DataFrame(X[['sentence', 'translation']].loc[test])\n",
    " \n",
    "    df_skf['y_true'] = y.loc[test]\n",
    "    df_skf['pred'] = y_pred\n",
    "    df_skf.to_csv(f\"../data/processed/classification_results/liver_is_enlarged_result_{i}.csv\", index=False)\n",
    "    \n",
    "    acc = accuracy_score(y.loc[test], y_pred)\n",
    "    f1 = f1_score(y.loc[test], y_pred)\n",
    "    acc_scores.append(round(acc, 4))\n",
    "    f1_scores.append(round(f1, 4))\n",
    "    conf_scores.append(confusion_matrix(y.loc[test], y_pred))\n",
    "    i += 1\n",
    "print(f\"confusion matrix score:\\n{sum(conf_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc scores: [0.94, 0.94, 0.98, 0.94, 0.98]\n",
      "Mean acc: 0.9560\n",
      "\n",
      "F1 scores: [0.5714, 0.5714, 0.8571, 0.6667, 0.8571]\n",
      "Mean f1: 0.7047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acc scores: {acc_scores}\\nMean acc: {sum(acc_scores)/len(acc_scores):.4f}\\n\")\n",
    "print(f\"F1 scores: {f1_scores}\\nMean f1: {sum(f1_scores)/len(f1_scores):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
